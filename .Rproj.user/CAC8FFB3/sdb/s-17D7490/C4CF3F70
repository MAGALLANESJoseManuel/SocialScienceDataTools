{
    "contents" : "R TUTORIAL (III)\n========================================================\n```{r echo=FALSE, set-options }\noptions(width = 320)\n```\nWhen data you need is from different sources, you will nedd to have a clear integration strategy. For this section we will collect some data from the web, clean them and combine them into a single file.\n\nAs I will need to **scrap** many data sites, it is important to create a procedure that improves readability and makes coding more efficient. This function will look like this:\n\n```{r }\nscrapData <- function(linkWhere,whichTable,toFactor=FALSE) \n  {  require(XML) \n     dirtyTable <- getNodeSet(htmlParse(linkWhere),\"//table\") [[whichTable]]\n     tableToReturn <- readHTMLTable(dirtyTable,   #the generated above\n                                    header=TRUE,  #first line is the header\n                                    trim=TRUE,    #eliminate leading and trailing white spaces in cells\n                                    stringsAsFactors = toFactor #do not convert strings to factors\n                                    ) }\n\n```\n\nI took care to organise the input parameters in such a way that it is flexible to the way the data in the web page is presented. As it is clear from the function, we always need to provide a *link* and to indicate *which table* to scrap, and optionally inform if we need to convert strings to factors.\n\nSuppose that in this tutorial I want to organise some data at a country level by integrating some composite indexes. In this case, I will use the Indices of Freedom :\n<img src=\"http://i.imgur.com/hm7jOcA.png?1\"height=\"500\" width=\"800\" align=center> \n\nAnd the Global terrorism index:  \n<img src=\"http://i.imgur.com/I5BwHJN.png\"height=\"500\" width=\"500\" align=center> \n\nSince I think it might be neccessary some information on the location of the countries, I will get the region of the country from **cloford.com**:\n\n<img src=\"http://i.imgur.com/uJTk7Qx.png\"height=\"500\" width=\"800\" align=center> \n\nSo, these are links needed:\n```{r message=FALSE}\nfreedomLink = \"http://en.wikipedia.org/wiki/List_of_Indices_of_Freedom\"\nterrorismLink = \"http://en.wikipedia.org/wiki/Global_Terrorism_Index\"\nregionsLink=\"http://cloford.com/resources/codes/\"\n```\n\nNext, I apply the function to them:\n```{r}\nFreedom<-scrapData(freedomLink,3)\nTerrorism<-scrapData(terrorismLink,1)\nRegions<-scrapData(regionsLink,5)\n```\n\nI also have the Human Development Index in a web repository in a simple csv format:\n\n```{r message=FALSE}\nlibrary(RCurl)\ndata <- getURL(\"https://raw.github.com/MAGALLANESJoseManuel/SocialScienceDataTools/master/TemplatesR/hdi.csv\")\nHDI <- read.csv(text = data)\n```\n\nI combine the 3 data sets into *dataCountries*. For that, I have identified that they all have a column named \"Country\": \n```{r}\ndataCountries <- merge(Regions, Freedom, by= \"Country\")\ndataCountries <- merge(dataCountries, Terrorism, by= \"Country\")\ndataCountries <- merge(dataCountries, HDI, by= \"Country\")\n```\nLet's see what is the result so far:\n```{r}\nstr(dataCountries)\n```\n\n\nIt is important to notice that the every dataset had different number of countries, I will not do the cleaning of that (but should be done). So, I am conscious that I will have a smaller set of countries. For now, let's play attention to what variables I have:\n```{r}\nstr(dataCountries)\n```\nThere are some variables I do not want, so I make them dissapear:\n```{r}\ndataCountries <- dataCountries[c(-4:-10,-13,-15)] #I do not want these variable\n```\n\nFollowing, I alter the names of the variables:\n```{r}\nnames(dataCountries)=c(\"Country\",\"Continent\", \"Region\",\"Freedom\",\"FreeMarket\",\"Democracy\",\"Terrorism\", \"HDI\")\n```\n\nThese is what I have so far:\n```{r}\nsummary(dataCountries)\nstr(dataCountries)\nhead(dataCountries)\n```\nWe see nonstandard **n/a** values, and a mix of **number and category** which may bear trouble later, and also some columns should be read as factors and numbers but those are being read as characters, so we better change all of that.\n\nFirst we get find the cells that use \"n/a\", get the index and then go back to the cell and eliminate that:\n```{r}\nfor (i in 3:8){\nindexes=c(grep(\"/\", dataCountries[,i])) # where is it?\nif (length(indexes)>1)\n  dataCountries[indexes,i]=NA      # making the change  \n} \n```\n\nIn similar fashion we can find the cell whose that starts with a number and a space, and replace that combination by *nothing*:\n```{r}\nfor (i in 1:7){\n  dataCountries[i]=sub(\"[0-9]+ \", \"\", dataCountries[,i]) \n}\n```\n\nFinally,we change the type of the columns:\n```{r}\nfor (i in 2:7) {\n  if (i>6) {dataCountries[,i]=as.double(dataCountries[,i])}\n  else {dataCountries[,i]=as.factor(dataCountries[,i])}\n}\nsummary(dataCountries)\n```\n\nBut, we will only wish to have those countries with all the indexes, which will finally save as a csv file:\n```{r}\ndataCountries=na.omit(dataCountries)\nsetwd(\"~/Documents/GITHUBrepositories/Tutorials/TemplatesR\")\nwrite.csv(dataCountries,\"dataCountries.csv\",row.names=FALSE)\n```\n\nYou can access this data with the code:\n```{r}\nlibrary(RCurl)\nDATA_GithubCleaned <- getURL(\"https://raw.github.com/MAGALLANESJoseManuel/SocialScienceDataTools/master/TemplatesR/dataCountries.csv\")\nDATA_gitClean <- read.csv(text = DATA_GithubCleaned)\nhead(DATA_gitClean)\nstr(DATA_gitClean)\n\n```",
    "created" : 1396241694904.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1667192199",
    "id" : "C4CF3F70",
    "lastKnownWriteTime" : 1396234688,
    "path" : "~/Documents/GITHUBrepositories/Tutorials/TemplatesR/RTutor3.Rmd",
    "project_path" : "TemplatesR/RTutor3.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}