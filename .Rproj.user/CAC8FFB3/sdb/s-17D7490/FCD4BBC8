{
    "contents" : "R TUTORIAL (II)\n========================================================\n```{r echo=FALSE}\noptions(width = 320)\n```\nIn a previous post we had a table from wikipedia with information of interest. In this code, I will show some variations in data **collection** and **cleaning**.  \n\nFollowing from the previous tutorial we had a table from the link:\n```{r}\nLink = \"http://en.wikipedia.org/wiki/List_of_border_wars\"\n```\n\nAs it can be seen below, this wikipage has many tables:\n\n<img src=\"http://i.imgur.com/hOa1tml.jpg\" height=\"500\" width=\"800\" align=center> \n\nFirst, let's get the table as in the previous post:\n\n```{r}\nlibrary(XML)\nwhichTable=3\ndirtyTable = getNodeSet(htmlParse(Link),\"//table\") [[whichTable]]\n```\n\nThen, let's get the **table** already known, and see its first rows(using *head*):\n```{r echo=FALSE, cache=FALSE}\ncleanTable = readHTMLTable(dirtyTable)\ncleanTable\n```\n\nThe code so far is not recognising the first row as the names of the columns, so we solve that setting header as *True*:\n\n```{r}\ncleanTable = readHTMLTable(dirtyTable,header=T)\ncleanTable\n```\n\nNow we are concern with the strange characters in the fourth column, we will try to see if indicating UTF-8 as encoding can help solve this situation:\n```{r}\ndirtyTable = getNodeSet(htmlParse(Link,encoding=\"UTF-8\"),\"//table\") [[whichTable]]\ncleanTable = readHTMLTable(dirtyTable,header=T)\ncleanTable\n```\n\nThis is so much better. Now that we have got rid of the most obvious issues, let's see if we other things are hidding somewhere.Let's simply get a *summary* and the *structure* of this table:\n```{r results='hold'}\nsummary(cleanTable)\nstr(cleanTable)\n```\n\nThe last column has obvious problems, and we can try to replace the wrong symbols. However, from the last result we see it is a factor instead of a string, we need to correct that (if it is not a string, we can not operate on them with string functions).\n\n```{r}\ndirtyTable = getNodeSet(htmlParse(Link,encoding=\"UTF-8\"),\"//table\") [[whichTable]]\ncleanTable = readHTMLTable(dirtyTable,header=T,trim=T,stringsAsFactors = F)\nindexmillion=grep(\"million\", cleanTable$Fatalities)\ncleanTable$Fatalities[indexmillion]='2000000'\nindexunknown=grep(\"Un\", cleanTable$Fatalities)\ncleanTable$Fatalities[c(indexunknown)]=NA\ncleanTable\n```\n\nWe see a better table. Now we need to get rid of those problematic symbols and empty spaces.We will extra columns to show the conversion process.\n```{r}\ncleanTable$Fatalities2=gsub(\"[[:punct:]]\", \"\", cleanTable$Fatalities)\ncleanTable$Fatalities3=gsub(\" \", \"\", cleanTable$Fatalities2)\ncleanTable\n```\n\n```{r}\ncleanTable$Fatalities=as.numeric(cleanTable$Fatalities3)\ncleanTable$Fatalities2=NULL\ncleanTable$Fatalities3=NULL\ncleanTable\n```\n\nThe final step would the to clean the cell where a problematic text is input for *finish* year:\n```{r}\nindexyear=grep(\"CF\", cleanTable$Finish)\ncleanTable$Finish[indexyear]='1953'\n```\n\nWe can now save the file to our github repository (once we push it from Rstudio):\n```{r}\nsetwd(\"~/Documents/GITHUBrepositories/Tutorials/TemplatesR\")\nwrite.csv(cleanTable,\"wikitable.csv\")\n```\n\nYou can work with this file now:\n```{r}\nlibrary(RCurl)\nDATA_GithubCleaned <- getURL(\"https://raw.github.com/MAGALLANESJoseManuel/SocialScienceDataTools/master/TemplatesR/wikitable.csv\")\nDATA_gitClean <- read.csv(text = DATA_GithubCleaned)\nhead(DATA_gitClean)\n```\n",
    "created" : 1396240810507.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3155670307",
    "id" : "FCD4BBC8",
    "lastKnownWriteTime" : 1396234688,
    "path" : "~/Documents/GITHUBrepositories/Tutorials/TemplatesR/RTutor2.Rmd",
    "project_path" : "TemplatesR/RTutor2.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}